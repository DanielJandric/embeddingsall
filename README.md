# SystÃ¨me de Traitement de Documents avec OCR, Embeddings et Supabase

Un pipeline complet pour traiter des documents (images et PDFs), extraire le texte via Azure OCR, gÃ©nÃ©rer des embeddings avec OpenAI, et stocker les rÃ©sultats dans Supabase pour la recherche sÃ©mantique.

## ğŸš€ FonctionnalitÃ©s

- **OCR Azure** : Extraction de texte depuis images et PDFs avec Azure Form Recognizer
- **Embeddings OpenAI** : GÃ©nÃ©ration d'embeddings vectoriels pour la recherche sÃ©mantique
- **Supabase** : Stockage et recherche vectorielle dans une base de donnÃ©es cloud
- **Traitement par lots** : Support pour le traitement de grandes quantitÃ©s de documents
- **Chunking intelligent** : DÃ©coupage automatique des longs textes avec chevauchement
- **Retry automatique** : Gestion robuste des erreurs avec retry exponentiel

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- Un compte Azure avec Cognitive Services (Form Recognizer)
- Une clÃ© API OpenAI
- Un projet Supabase

## ğŸ”§ Installation

1. **Cloner le dÃ©pÃ´t**
```bash
git clone <votre-repo>
cd embeddingsall
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**
```bash
cp .env.example .env
```

Ã‰ditez le fichier `.env` avec vos clÃ©s API :

```env
# Azure Cognitive Services
AZURE_FORM_RECOGNIZER_ENDPOINT=https://votre-resource.cognitiveservices.azure.com/
AZURE_FORM_RECOGNIZER_KEY=votre_cle_azure

# OpenAI
OPENAI_API_KEY=sk-votre_cle_openai
EMBEDDING_MODEL=text-embedding-3-small

# Supabase
SUPABASE_URL=https://votre-projet.supabase.co
SUPABASE_KEY=votre_cle_supabase

# Configuration
BATCH_SIZE=100
CHUNK_SIZE=1000
MAX_WORKERS=4
```

## ğŸ—„ï¸ Configuration Supabase

Avant d'utiliser le script, crÃ©ez la table dans Supabase avec cette requÃªte SQL :

```sql
-- Activer l'extension pour les vecteurs
CREATE EXTENSION IF NOT EXISTS vector;

-- CrÃ©er la table documents
CREATE TABLE IF NOT EXISTS documents (
    id BIGSERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding VECTOR(1536),  -- Pour text-embedding-3-small
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- CrÃ©er un index pour la recherche vectorielle
CREATE INDEX documents_embedding_idx
ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- CrÃ©er un index sur les mÃ©tadonnÃ©es
CREATE INDEX documents_metadata_idx
ON documents
USING GIN (metadata);

-- Fonction pour la recherche de similaritÃ©
CREATE OR REPLACE FUNCTION match_documents (
  query_embedding VECTOR(1536),
  match_threshold FLOAT,
  match_count INT
)
RETURNS TABLE (
  id BIGINT,
  content TEXT,
  metadata JSONB,
  similarity FLOAT
)
LANGUAGE SQL STABLE
AS $$
  SELECT
    id,
    content,
    metadata,
    1 - (embedding <=> query_embedding) AS similarity
  FROM documents
  WHERE 1 - (embedding <=> query_embedding) > match_threshold
  ORDER BY similarity DESC
  LIMIT match_count;
$$;
```

## ğŸ“ Utilisation

### Traiter un fichier unique

```bash
python main.py -i data/input/document.pdf -o data/processed
```

### Traiter un rÃ©pertoire complet

```bash
python main.py -i data/input -o data/processed
```

### Traiter et uploader vers Supabase

```bash
python main.py -i data/input -o data/processed --upload --table documents
```

### Options disponibles

```
usage: main.py [-h] -i INPUT [-o OUTPUT] [-t TABLE] [--upload]
               [--log-level {DEBUG,INFO,WARNING,ERROR}] [--log-file LOG_FILE]

Arguments:
  -i, --input      RÃ©pertoire ou fichier d'entrÃ©e (requis)
  -o, --output     RÃ©pertoire de sortie pour les JSON (dÃ©faut: data/processed)
  -t, --table      Nom de la table Supabase (dÃ©faut: documents)
  --upload         Upload les rÃ©sultats vers Supabase
  --log-level      Niveau de logging (dÃ©faut: INFO)
  --log-file       Fichier de log optionnel
```

## ğŸ“ Structure du projet

```
embeddingsall/
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ .env.example           # Exemple de configuration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ azure_ocr.py       # Module OCR Azure
â”‚   â”œâ”€â”€ embeddings.py      # Module gÃ©nÃ©ration d'embeddings
â”‚   â”œâ”€â”€ supabase_client.py # Module client Supabase
â”‚   â””â”€â”€ logger.py          # Configuration du logging
â””â”€â”€ data/
    â”œâ”€â”€ input/             # Documents Ã  traiter
    â””â”€â”€ processed/         # RÃ©sultats JSON
```

## ğŸ”„ Workflow

1. **Extraction OCR** : Le texte est extrait des documents (images/PDFs) via Azure Form Recognizer
2. **Chunking** : Les longs textes sont dÃ©coupÃ©s en chunks avec chevauchement
3. **Embeddings** : Chaque chunk est transformÃ© en vecteur d'embedding via OpenAI
4. **Sauvegarde locale** : Les rÃ©sultats sont sauvegardÃ©s en JSON
5. **Upload Supabase** : Les embeddings sont uploadÃ©s dans Supabase (optionnel)

## ğŸ’¡ Exemples d'utilisation

### Utilisation programmatique

```python
from src.azure_ocr import AzureOCRProcessor
from src.embeddings import EmbeddingGenerator
from src.supabase_client import SupabaseUploader

# Initialiser les processeurs
ocr = AzureOCRProcessor()
embedder = EmbeddingGenerator()
uploader = SupabaseUploader()

# Traiter un document
ocr_result = ocr.process_file("document.pdf")
embeddings = embedder.process_ocr_result(ocr_result)

# Upload vers Supabase
uploader.upload_embeddings("documents", embeddings)
```

### Recherche sÃ©mantique

```python
from src.embeddings import EmbeddingGenerator
from src.supabase_client import SupabaseUploader

# GÃ©nÃ©rer l'embedding de la requÃªte
embedder = EmbeddingGenerator()
query_embedding = embedder.generate_embedding("Qu'est-ce que l'IA?")

# Rechercher dans Supabase
uploader = SupabaseUploader()
results = uploader.search_similar(
    table_name="documents",
    query_embedding=query_embedding,
    limit=5,
    threshold=0.7
)

for result in results:
    print(f"SimilaritÃ©: {result['similarity']:.2f}")
    print(f"Contenu: {result['content'][:200]}...")
    print("---")
```

## ğŸ¯ Formats supportÃ©s

- **Images** : JPG, JPEG, PNG, BMP, TIFF, TIF
- **Documents** : PDF

## âš¡ Performance

- Traitement par lots pour optimiser les appels API
- Retry automatique avec backoff exponentiel
- Chunking intelligent pour gÃ©rer les longs documents
- Support du traitement parallÃ¨le (configurable)

## ğŸ”’ SÃ©curitÃ©

- Les clÃ©s API sont stockÃ©es dans des variables d'environnement
- Le fichier `.env` est dans `.gitignore`
- Utilisation de HTTPS pour toutes les communications API

## ğŸ› DÃ©pannage

### Erreur "Azure endpoint et key doivent Ãªtre fournis"
- VÃ©rifiez que votre fichier `.env` contient les bonnes clÃ©s
- Assurez-vous que le fichier `.env` est Ã  la racine du projet

### Erreur "Table does not exist"
- ExÃ©cutez les requÃªtes SQL de configuration dans Supabase
- VÃ©rifiez que l'extension `vector` est activÃ©e

### Erreur de rate limit OpenAI
- RÃ©duisez `BATCH_SIZE` dans `.env`
- Le systÃ¨me retry automatiquement avec backoff

## ğŸ“Š Monitoring

Le script gÃ©nÃ¨re des logs dÃ©taillÃ©s :

```bash
# Avec logs dans un fichier
python main.py -i data/input --upload --log-file logs/processing.log

# Avec niveau DEBUG
python main.py -i data/input --log-level DEBUG
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Ouvrir des issues pour les bugs
- Proposer des amÃ©liorations
- Soumettre des pull requests

## ğŸ“„ Licence

Ce projet est sous licence MIT.

## ğŸ™ Remerciements

- Azure Cognitive Services pour l'OCR
- OpenAI pour les embeddings
- Supabase pour la base de donnÃ©es vectorielle

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur GitHub.
