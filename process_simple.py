#!/usr/bin/env python3
"""
Script SIMPLE de traitement SÃ‰QUENTIEL (sans parallÃ¨le)
Plus lent mais avec logs visibles
"""

import os
import sys
import argparse
from pathlib import Path
from dotenv import load_dotenv

# Import des modules
from src.pdf_extractor import extract_text_from_pdf
from src.embeddings import EmbeddingGenerator
from src.supabase_client import SupabaseUploader

load_dotenv()

def detect_file_type(file_path):
    """DÃ©tecte le type de fichier"""
    ext = Path(file_path).suffix.lower()
    if ext in ['.txt', '.md', '.csv', '.json', '.xml', '.html']:
        return 'text'
    elif ext in ['.pdf']:
        return 'pdf'
    elif ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']:
        return 'image'
    else:
        return 'unknown'


def process_one_file(file_path, embedding_generator, supabase_uploader, upload=True):
    """Traite UN fichier et affiche les logs"""

    file_name = Path(file_path).name
    file_type = detect_file_type(file_path)

    print(f"\n{'='*70}")
    print(f"ğŸ“„ {file_name}")
    print(f"{'='*70}")

    try:
        # 1. Extraction du texte
        print(f"ğŸ“– Type: {file_type}")

        if file_type == 'text':
            print("ğŸ“– Lecture du fichier texte...")
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()

        elif file_type == 'pdf':
            print("ğŸ“– Extraction du texte du PDF...")
            text = extract_text_from_pdf(file_path)

            if not text or len(text.strip()) < 100:
                print("âš ï¸  Pas assez de texte extrait")
                return {'success': False, 'file': file_name, 'error': 'PDF scannÃ© ou vide'}

        else:
            print(f"âŒ Type de fichier non supportÃ©: {file_type}")
            return {'success': False, 'file': file_name, 'error': f'Type non supportÃ©: {file_type}'}

        print(f"âœ… Texte extrait: {len(text)} caractÃ¨res")

        # 2. GÃ©nÃ©ration des embeddings
        print("ğŸ”¢ DÃ©coupage en chunks...")
        chunks = embedding_generator.chunk_text(text, chunk_size=1000, overlap=200)
        print(f"âœ… {len(chunks)} chunks crÃ©Ã©s")

        # Limiter Ã  100 chunks max
        if len(chunks) > 100:
            print(f"âš ï¸  Limitation Ã  100 chunks (au lieu de {len(chunks)})")
            chunks = chunks[:100]

        print(f"ğŸ”¢ GÃ©nÃ©ration de {len(chunks)} embeddings...")
        embeddings = embedding_generator.generate_embeddings_batch(chunks, batch_size=20)
        print(f"âœ… {len(embeddings)} embeddings gÃ©nÃ©rÃ©s")

        # 3. Upload vers Supabase
        if upload and embeddings:
            print("ğŸ’¾ PrÃ©paration des documents...")
            documents = []
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                if embedding:
                    documents.append({
                        "content": chunk,
                        "embedding": embedding,
                        "metadata": {
                            "file_path": str(file_path),
                            "file_name": file_name,
                            "file_type": file_type,
                            "chunk_index": i,
                            "total_chunks": len(chunks)
                        }
                    })

            print(f"ğŸ’¾ Upload de {len(documents)} documents vers Supabase...")
            supabase_uploader.upload_batch("documents", documents, batch_size=100)
            print(f"âœ… Upload terminÃ© !")

        return {'success': True, 'file': file_name, 'chunks': len(chunks)}

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'file': file_name, 'error': str(e)}


def main():
    parser = argparse.ArgumentParser(description="Traitement SIMPLE sÃ©quentiel")
    parser.add_argument("-i", "--input", required=True, help="Dossier Ã  traiter")
    parser.add_argument("--upload", action="store_true", help="Upload vers Supabase")
    parser.add_argument("--max-files", type=int, default=None, help="Limiter le nombre de fichiers")

    args = parser.parse_args()

    print("="*70)
    print("ğŸ“ TRAITEMENT SIMPLE SÃ‰QUENTIEL")
    print("="*70)

    # Lister les fichiers
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ Dossier {args.input} n'existe pas")
        return

    all_files = [f for f in input_path.rglob('*') if f.is_file() and not f.name.startswith('.')]

    if args.max_files:
        all_files = all_files[:args.max_files]

    print(f"\nğŸ“‚ Dossier: {input_path}")
    print(f"ğŸ“Š Fichiers Ã  traiter: {len(all_files)}")

    if len(all_files) == 0:
        print("âš ï¸  Aucun fichier")
        return

    # Initialiser les services
    print("\nğŸ”§ Initialisation...")

    embedding_generator = EmbeddingGenerator()
    print("âœ… Client OpenAI initialisÃ©")

    if args.upload:
        supabase_uploader = SupabaseUploader()
        print("âœ… Client Supabase initialisÃ©")
    else:
        supabase_uploader = None

    # Traitement SÃ‰QUENTIEL
    print("\nğŸš€ DÃ©but du traitement...\n")

    success_count = 0
    error_count = 0

    for i, file_path in enumerate(all_files, 1):
        print(f"\n[{i}/{len(all_files)}]")

        result = process_one_file(
            file_path,
            embedding_generator,
            supabase_uploader,
            args.upload
        )

        if result['success']:
            success_count += 1
        else:
            error_count += 1

    # RÃ©sumÃ©
    print("\n" + "="*70)
    print("ğŸ“Š RÃ‰SUMÃ‰")
    print("="*70)
    print(f"âœ… SuccÃ¨s: {success_count}")
    print(f"âŒ Erreurs: {error_count}")
    print(f"ğŸ“ Total: {len(all_files)}")

    if args.upload:
        print(f"\nğŸ’¾ Documents dans Supabase (table: documents)")

    print("\nğŸ‰ TerminÃ© !")


if __name__ == "__main__":
    main()
